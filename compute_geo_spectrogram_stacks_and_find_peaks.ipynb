{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stack the geophone spectrograms of all geophone stations and find the spectral peaks in the stacked spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from os.path import join\n",
    "from pandas import concat, Timestamp\n",
    "from time import time\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from utils_basic import SPECTROGRAM_DIR as indir, GEO_STATIONS as stations\n",
    "from utils_basic import get_geophone_days, get_geo_stations\n",
    "from utils_spec import find_geo_station_spectral_peaks, get_spectrogram_file_suffix, get_spec_peak_file_suffix \n",
    "from utils_spec import read_geo_spectrograms, read_geo_spec_headers, save_spectral_peaks\n",
    "from utils_plot import plot_geo_total_psd_and_peaks, save_figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "# Data\n",
    "window_length = 1.0\n",
    "overlap = 0.0\n",
    "downsample = False\n",
    "downsample_factor = 60\n",
    "\n",
    "# Finding peaks\n",
    "num_process = 32\n",
    "rbw_threshold = 0.2\n",
    "prom_threshold = 10\n",
    "min_freq = None\n",
    "max_freq = 200.0\n",
    "\n",
    "# Writing\n",
    "to_csv = False\n",
    "to_hdf = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the time labels to process\n",
    "days = get_geophone_days()\n",
    "time_labels = [Timestamp(day).strftime(\"%Y%m%d%H%M%S%f\") for day in days]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the stack and find the peaks for each time label\n",
    "suffix_spec = get_spectrogram_file_suffix(window_length, overlap, downsample, downsample_factor = downsample_factor)\n",
    "peak_dfs = []\n",
    "for time_label in time_labels:\n",
    "    print(f\"Processing {time_label}...\")\n",
    "\n",
    "    # Loop over stations to compute the stack\n",
    "    num_sta = 0\n",
    "    for i, station in enumerate(stations):\n",
    "        print(f:\"Processing {station}...\")\n",
    "\n",
    "        # Read the spectrogram blocks\n",
    "        filename = f\"whole_deployment_daily_geo_spectrograms_{station}_{suffix_spec}.h5\"\n",
    "        inpath = join(indir, filename)\n",
    "        stream_spec = read_geo_spectrograms(inpath, time_labels = [time_label])\n",
    "\n",
    "        if stream_spec is None:\n",
    "            print(f\"No data for {station} at {time_label}.\")\n",
    "            continue\n",
    "        else:\n",
    "            num_sta += 1\n",
    "\n",
    "        # Compute the total PSD\n",
    "        trace_spec_total = stream_spec.get_total_power()\n",
    "\n",
    "        # Stack the PSDs\n",
    "        if num_sta == 1:\n",
    "            trace_spec_stack = trace_spec_total.copy()\n",
    "        else:\n",
    "            trace_spec_stack[\"data\"] += trace_spec_total[\"data\"]\n",
    "\n",
    "    if num_sta == 0:\n",
    "        print(f\"No data for any station at {time_label}.\")\n",
    "        continue\n",
    "\n",
    "    # Divide by the number of stations\n",
    "    trace_spec_stack[\"data\"] /= num_sta\n",
    "\n",
    "    # Find the spectral peaks\n",
    "    peak_df = find_trace_spectral_peaks(trace_spec_stak, num_process, prom_threshold = prom_threshold, rbw_threshold = rbw_threshold, min_freq = min_freq, max_freq = max_freq)\n",
    "    num_peaks = len(peak_df)\n",
    "    print(f\"Found {num_peaks} peaks.\")\n",
    "\n",
    "    # Append to the list\n",
    "    peak_dfs.append(peak_df)\n",
    "print(\"Done.\")\n",
    "print(\"\")\n",
    "\n",
    "# Concatenate the peak dataframes\n",
    "print(\"Concatenating the peak dataframes...\")\n",
    "if len(peak_dfs) > 0:\n",
    "    peak_df = concat(peak_dfs, axis = 0)\n",
    "\n",
    "num_peaks = len(peak_df)\n",
    "print(f\"Total number of peaks: {num_peaks}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the peaks\n",
    "suffix_peak = get_spec_peak_file_suffix(prom_threshold, rbw_threshold, min_freq = min_freq, max_freq = max_freq)\n",
    "file_stem = f\"geo_stack_spectral_peaks_{suffix_spec}_{suffix_peak}\"\n",
    "\n",
    "if to_csv:\n",
    "    save_spectral_peaks(peak_df, file_stem, \"csv\")\n",
    "\n",
    "if to_hdf:\n",
    "    save_spectral_peaks(peak_df, file_stem, \"h5\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
